{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "024596a1",
   "metadata": {},
   "source": [
    "# Head Pose Estimation- Project\n",
    "\n",
    "- In this project we used AFLW2000 Dataset to read image and Extraxt landmarks from images\n",
    "- AFLW2000 conist of 2000 images and you can download from this link \n",
    "http://www.cbsr.ia.ac.cn/users/xiangyuzhu/projects/3DDFA/main.htm\n",
    "\n",
    "- In this NoteBook steps we follow:\n",
    "  - Import libraries\n",
    "  - Read Images and Extract Landmarks\n",
    "  - Read and Prepare Data\n",
    "  - Train Machine Learning Models\n",
    "  - Save models \n",
    "  - Live Camera and Draw axises on faces\n",
    "\n",
    "\n",
    "### Team Members:\n",
    "   - Ahmad Khaled\n",
    "   - Aya Hassan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d552ff3c",
   "metadata": {
    "id": "d552ff3c"
   },
   "outputs": [],
   "source": [
    "# Install mediaPiPe and Open Cv\n",
    "\n",
    "# !pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504aeeae",
   "metadata": {},
   "source": [
    "# Import libararies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49828bef",
   "metadata": {
    "id": "49828bef"
   },
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from mat4py import loadmat\n",
    "import scipy.io as sio\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a736150",
   "metadata": {
    "id": "ee50dca5"
   },
   "source": [
    "### You can read more about holistic media pipe model from this Link\n",
    "- https://google.github.io/mediapipe/solutions/holistic.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc0099a6",
   "metadata": {
    "id": "bc0099a6"
   },
   "outputs": [],
   "source": [
    "# Drawing helpers in mediapipe\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Mediapipe Solutions\n",
    "mp_holistic = mp.solutions.holistic \n",
    "\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed69b7b",
   "metadata": {
    "id": "aed69b7b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f5724bd",
   "metadata": {
    "id": "0f5724bd"
   },
   "outputs": [],
   "source": [
    "paths = []\n",
    "# get the path/directory\n",
    "folder_dir =\"C:\\\\Users\\\\ahmad\\Downloads\\AFLW2000\"\n",
    "\n",
    "# iterate over files in\n",
    "# that directory\n",
    "for images in glob.iglob(f'{folder_dir}/*'):\n",
    "\n",
    "    # check if the image ends with png\n",
    "    if (images.endswith(\".jpg\")):\n",
    "#         print(images)\n",
    "        paths.append(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "772092a8",
   "metadata": {
    "id": "772092a8",
    "outputId": "3f99eda2-cb40-433d-f24f-8740042fe996"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Number of Paths in dataset directory\n",
    "len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ca8673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "309f5383",
   "metadata": {},
   "source": [
    "# Try media Pipe Model:\n",
    "- we try mediapipe model on our dataset ALFW2000 to learn how to access it and get landmarks from it\n",
    "- we try it on first image, so we use break statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7b64f26",
   "metadata": {
    "id": "d7b64f26"
   },
   "outputs": [],
   "source": [
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic: \n",
    "\n",
    "    for idx, file in enumerate(paths):\n",
    "        image = cv2.imread(file)\n",
    "        image_height, image_width, _ = image.shape\n",
    "        # Convert the BGR image to RGB before processing.\n",
    "        results = holistic.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "#         results = holistic.process(image)\n",
    "#         print(results.face_landmarks)\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        \n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7d1dcb0",
   "metadata": {
    "id": "c7d1dcb0",
    "outputId": "1989b609-0b64-46c9-f1e6-d183bafa95ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.47754186391830444\n",
       "y: 0.6920552253723145\n",
       "z: -0.018991734832525253"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# access Landmarks to use it \n",
    "results.face_landmarks.landmark[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6411df6",
   "metadata": {
    "id": "d6411df6",
    "outputId": "957fea64-911f-4b62-cade-d62a8d3f4525"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print Number of Landmarks extracted From Images which 468 points\n",
    "num_coords = len(results.face_landmarks.landmark)\n",
    "num_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "509665ef",
   "metadata": {
    "id": "509665ef"
   },
   "outputs": [],
   "source": [
    "landmarks = []\n",
    "\n",
    "# Create a list consist of (x1,y1) -> (x468,y468)\n",
    "for val in range(1, num_coords+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val)]\n",
    "# landmarks\n",
    "\n",
    "# insert lables in this list\n",
    "angles=['pitch','yaw','roll']\n",
    "data = landmarks+angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32688cf1",
   "metadata": {
    "id": "32688cf1"
   },
   "outputs": [],
   "source": [
    "# Create CSV File with headers using the list of Landmarks as our CSV file headers\n",
    "\n",
    "with open('landmarks_data.csv', mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "502410ba",
   "metadata": {
    "id": "502410ba",
    "outputId": "9f38f235-0c3c-43d3-eed8-687d71f040f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'image00002'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split to get the name of the file \n",
    "paths[0].split('\\\\')[-1].replace('.jpg','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e35e4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14c81a96",
   "metadata": {},
   "source": [
    "## Read Images & Extract Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36168297",
   "metadata": {
    "id": "36168297"
   },
   "outputs": [],
   "source": [
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "\n",
    "    for idx, file in enumerate(paths):\n",
    "        count=0\n",
    "        image = cv2.imread(file)\n",
    "        image_height, image_width, _ = image.shape\n",
    "#         Convert the BGR image to RGB before processing.\n",
    "        results = holistic.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        try:\n",
    "           \n",
    "            # Get all face landmarks points axis(xn , yn) n =1 -> 468 \n",
    "            face = results.face_landmarks.landmark\n",
    "            \n",
    "            # get x-axis value of Nose\n",
    "            NoseX = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].x * image_width\n",
    "            \n",
    "            # get y-axis value of Nose\n",
    "            NoseY=results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].y   *image_height\n",
    "            \n",
    "            # get x-axis value of left eye outer\n",
    "            LfeoX = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EYE_OUTER].x *image_width\n",
    "            \n",
    "            # get y-axis value of left eye outer\n",
    "            LfeoY = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EYE_OUTER].y* image_height\n",
    "            \n",
    "            # Calculate the distance between Nose and Outer Left Eye\n",
    "            dist = math.dist([NoseX, NoseY], [LfeoX, LfeoY])\n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            # In this block Normalize Data getting from Image in Dataset anf flatten it to 1-D array\n",
    "            face_row = list(np.array([[   ((landmark.x *image_width)-NoseX)/dist, \n",
    "                                            ((landmark.y*image_height)-NoseY)/dist] for landmark in face]).flatten())\n",
    "            \n",
    "            # Get the name of file for ex:\"image2000\"\n",
    "            random_file = file.split('\\\\')[-1].replace('.jpg' , '')\n",
    "            \n",
    "            # Read the Matlab file of the image to get labels\n",
    "            mat_file = sio.loadmat('C:\\\\Users\\\\ahmad\\\\Downloads\\\\AFLW2000\\\\'+ random_file+ '.mat')\n",
    "            \n",
    "            # We can find labels(Pitch, Yaw , Roll) angles in pose_para in the mat file\n",
    "            pose_para = mat_file[\"Pose_Para\"][0][:3]\n",
    "            \n",
    "            # get pitch angle\n",
    "            pitch = pose_para[0]\n",
    "            \n",
    "            # get Yaw angle\n",
    "            yaw = pose_para[1]\n",
    "            \n",
    "            # Get Roll angle\n",
    "            roll = pose_para[2]\n",
    "            \n",
    "            # Append lables in the list named face_row\n",
    "            face_row.insert(((468*2)+0),pitch)\n",
    "            face_row.insert(((468*2)+1),yaw)\n",
    "            face_row.insert(((468*2)+2),roll)\n",
    "            \n",
    "            # append the Face_row list to our CSV file\n",
    "            with open('landmarks_data.csv', mode='a', newline='') as f:\n",
    "                csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                csv_writer.writerow(face_row) \n",
    "                \n",
    "        except:\n",
    "            pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590c07ae",
   "metadata": {
    "id": "590c07ae"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51c70889",
   "metadata": {
    "id": "51c70889"
   },
   "source": [
    "# Read and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51df8af8",
   "metadata": {
    "id": "51df8af8"
   },
   "outputs": [],
   "source": [
    "# Import pandas to deal with data \n",
    "import pandas as pd\n",
    "\n",
    "# import train_test_split to split our data to train,validation,test datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ecc94e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "9ecc94e1",
    "outputId": "04e31d63-76b8-4de1-b201-29c2da105b17"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y4</th>\n",
       "      <th>x5</th>\n",
       "      <th>y5</th>\n",
       "      <th>...</th>\n",
       "      <th>y465</th>\n",
       "      <th>x466</th>\n",
       "      <th>y466</th>\n",
       "      <th>x467</th>\n",
       "      <th>y467</th>\n",
       "      <th>x468</th>\n",
       "      <th>y468</th>\n",
       "      <th>pitch</th>\n",
       "      <th>yaw</th>\n",
       "      <th>roll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.159295</td>\n",
       "      <td>0.300003</td>\n",
       "      <td>-0.169120</td>\n",
       "      <td>0.067671</td>\n",
       "      <td>-0.146352</td>\n",
       "      <td>0.109180</td>\n",
       "      <td>-0.190952</td>\n",
       "      <td>-0.301066</td>\n",
       "      <td>-0.161892</td>\n",
       "      <td>-0.022124</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.640003</td>\n",
       "      <td>0.132219</td>\n",
       "      <td>-0.604989</td>\n",
       "      <td>0.751723</td>\n",
       "      <td>-0.761274</td>\n",
       "      <td>0.807323</td>\n",
       "      <td>-0.806983</td>\n",
       "      <td>-0.399231</td>\n",
       "      <td>0.018227</td>\n",
       "      <td>0.085676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.334478</td>\n",
       "      <td>0.261430</td>\n",
       "      <td>-0.472663</td>\n",
       "      <td>-0.051103</td>\n",
       "      <td>-0.284650</td>\n",
       "      <td>0.053159</td>\n",
       "      <td>-0.358159</td>\n",
       "      <td>-0.332285</td>\n",
       "      <td>-0.480441</td>\n",
       "      <td>-0.137888</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.525273</td>\n",
       "      <td>0.037087</td>\n",
       "      <td>-0.505745</td>\n",
       "      <td>0.562256</td>\n",
       "      <td>-0.565438</td>\n",
       "      <td>0.632099</td>\n",
       "      <td>-0.617696</td>\n",
       "      <td>0.470065</td>\n",
       "      <td>1.189533</td>\n",
       "      <td>0.300959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.981481</td>\n",
       "      <td>1.076963</td>\n",
       "      <td>-0.956155</td>\n",
       "      <td>0.954189</td>\n",
       "      <td>-0.976846</td>\n",
       "      <td>0.985318</td>\n",
       "      <td>-1.013231</td>\n",
       "      <td>0.778098</td>\n",
       "      <td>-0.954629</td>\n",
       "      <td>0.903266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.634062</td>\n",
       "      <td>-0.919076</td>\n",
       "      <td>0.647000</td>\n",
       "      <td>-0.675460</td>\n",
       "      <td>0.588512</td>\n",
       "      <td>-0.651586</td>\n",
       "      <td>0.567591</td>\n",
       "      <td>-0.184650</td>\n",
       "      <td>0.881137</td>\n",
       "      <td>-0.236852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.127447</td>\n",
       "      <td>0.433119</td>\n",
       "      <td>-0.086203</td>\n",
       "      <td>0.200610</td>\n",
       "      <td>0.035008</td>\n",
       "      <td>0.228611</td>\n",
       "      <td>-0.239562</td>\n",
       "      <td>-0.172509</td>\n",
       "      <td>-0.133581</td>\n",
       "      <td>0.104239</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.642603</td>\n",
       "      <td>0.021166</td>\n",
       "      <td>-0.595805</td>\n",
       "      <td>0.629668</td>\n",
       "      <td>-0.972822</td>\n",
       "      <td>0.673793</td>\n",
       "      <td>-1.040024</td>\n",
       "      <td>-0.175379</td>\n",
       "      <td>0.299208</td>\n",
       "      <td>-0.373374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.078761</td>\n",
       "      <td>0.400796</td>\n",
       "      <td>-0.344684</td>\n",
       "      <td>0.090758</td>\n",
       "      <td>-0.104594</td>\n",
       "      <td>0.147864</td>\n",
       "      <td>-0.317465</td>\n",
       "      <td>-0.235742</td>\n",
       "      <td>-0.383646</td>\n",
       "      <td>-0.000681</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.595326</td>\n",
       "      <td>-0.004369</td>\n",
       "      <td>-0.552671</td>\n",
       "      <td>0.427108</td>\n",
       "      <td>-0.790101</td>\n",
       "      <td>0.482372</td>\n",
       "      <td>-0.853066</td>\n",
       "      <td>-0.882169</td>\n",
       "      <td>1.198003</td>\n",
       "      <td>-1.033374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 939 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        y1        x2        y2        x3        y3        x4  \\\n",
       "0 -0.159295  0.300003 -0.169120  0.067671 -0.146352  0.109180 -0.190952   \n",
       "1 -0.334478  0.261430 -0.472663 -0.051103 -0.284650  0.053159 -0.358159   \n",
       "2 -0.981481  1.076963 -0.956155  0.954189 -0.976846  0.985318 -1.013231   \n",
       "3  0.127447  0.433119 -0.086203  0.200610  0.035008  0.228611 -0.239562   \n",
       "4 -0.078761  0.400796 -0.344684  0.090758 -0.104594  0.147864 -0.317465   \n",
       "\n",
       "         y4        x5        y5  ...      y465      x466      y466      x467  \\\n",
       "0 -0.301066 -0.161892 -0.022124  ... -0.640003  0.132219 -0.604989  0.751723   \n",
       "1 -0.332285 -0.480441 -0.137888  ... -0.525273  0.037087 -0.505745  0.562256   \n",
       "2  0.778098 -0.954629  0.903266  ...  0.634062 -0.919076  0.647000 -0.675460   \n",
       "3 -0.172509 -0.133581  0.104239  ... -0.642603  0.021166 -0.595805  0.629668   \n",
       "4 -0.235742 -0.383646 -0.000681  ... -0.595326 -0.004369 -0.552671  0.427108   \n",
       "\n",
       "       y467      x468      y468     pitch       yaw      roll  \n",
       "0 -0.761274  0.807323 -0.806983 -0.399231  0.018227  0.085676  \n",
       "1 -0.565438  0.632099 -0.617696  0.470065  1.189533  0.300959  \n",
       "2  0.588512 -0.651586  0.567591 -0.184650  0.881137 -0.236852  \n",
       "3 -0.972822  0.673793 -1.040024 -0.175379  0.299208 -0.373374  \n",
       "4 -0.790101  0.482372 -0.853066 -0.882169  1.198003 -1.033374  \n",
       "\n",
       "[5 rows x 939 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read CSV file as DataFrame\n",
    "df=pd.read_csv('landmarks_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e80bc97f",
   "metadata": {
    "id": "e80bc97f"
   },
   "outputs": [],
   "source": [
    "#Features\n",
    "x=df.drop(['pitch','yaw','roll'], axis=1)\n",
    "#Pitch label\n",
    "yp=df['pitch']\n",
    "#Yaw label\n",
    "yy=df['yaw']\n",
    "#roll label\n",
    "yr=df['roll']\n",
    "#labels\n",
    "yall =df[['pitch','yaw','roll']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1add621b",
   "metadata": {
    "id": "1add621b"
   },
   "outputs": [],
   "source": [
    "#************************************************ PITCH ****************************************************************\n",
    "\n",
    "X_train_p, X_val_p, y_train_p, y_val_p = train_test_split(x, yp, test_size=0.2,shuffle=True, random_state=1234)\n",
    "\n",
    "X_val_p, X_test_p, y_val_p, y_test_p = train_test_split(X_val_p, y_val_p, test_size=0.5,shuffle=True, random_state=1234)\n",
    "\n",
    "\n",
    "#************************************************* YAW ******************************************************************\n",
    "\n",
    "X_train_y, X_val_y, y_train_y, y_val_y = train_test_split(x, yy, test_size=0.2, shuffle=True,random_state=1234)\n",
    "\n",
    "X_val_y, X_test_y, y_val_y, y_test_y = train_test_split(X_val_y, y_val_y, test_size=0.5, shuffle=True,random_state=1234)\n",
    "\n",
    "\n",
    "#*********************************************** Roll *******************************************************************\n",
    "\n",
    "X_train_r, X_val_r, y_train_r, y_val_r = train_test_split(x, yr, test_size=0.2,shuffle=True, random_state=1234)\n",
    "\n",
    "X_val_r, X_test_r, y_val_r, y_test_r = train_test_split(X_val_r, y_val_r, test_size=0.5,shuffle=True, random_state=1234)\n",
    "\n",
    "\n",
    "#*************************************************** ALL ****************************************************************\n",
    "\n",
    "\n",
    "X_train_all, X_val_all, y_train_all, y_val_all = train_test_split(x, yall, test_size=0.2,shuffle=True, random_state=1234)\n",
    "\n",
    "X_val_all, X_test_all, y_val_all, y_test_all = train_test_split(X_val_all, y_val_all, test_size=0.5,shuffle=True, random_state=1234)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796f373c",
   "metadata": {
    "id": "796f373c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a512e684",
   "metadata": {
    "id": "a512e684"
   },
   "source": [
    "# Train Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76cae38d",
   "metadata": {
    "id": "76cae38d"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, MaxAbsScaler, QuantileTransformer, PowerTransformer, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge , ridge_regression,Lasso\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor,BaggingRegressor,ExtraTreesRegressor\n",
    "from sklearn.pipeline import make_pipeline, FeatureUnion\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "from sklearn.datasets import make_regression\n",
    "import sklearn.linear_model\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "JBwoQdUAcCLu",
   "metadata": {
    "id": "JBwoQdUAcCLu"
   },
   "outputs": [],
   "source": [
    "# Create Models to Use in PiPeLine\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "bagging = BaggingRegressor(base_estimator=ExtraTreesRegressor(),n_estimators=10, random_state=0)\n",
    "\n",
    "boosting = GradientBoostingRegressor()\n",
    "\n",
    "svm= SVR()\n",
    "\n",
    "adaboost = AdaBoostRegressor()\n",
    "\n",
    "trees = ExtraTreesRegressor()\n",
    "\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53edd65",
   "metadata": {
    "id": "c53edd65"
   },
   "source": [
    "# YAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d98830f4",
   "metadata": {
    "id": "d98830f4"
   },
   "outputs": [],
   "source": [
    "#Create PipeLine to train our Data for Yaw angle\n",
    "pipelines = {\n",
    "        'rf_pca':make_pipeline(StandardScaler(),PCA(n_components=0.98), \n",
    "        VotingRegressor(estimators=[('RF',rf),('Bagging',bagging),('Boosting',boosting)]))\n",
    "            \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3de2f290",
   "metadata": {
    "id": "3de2f290"
   },
   "outputs": [],
   "source": [
    "#create a dictionary of trained models and its name\n",
    "yaw_fit_models = {}\n",
    "\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train_y, y_train_y)\n",
    "    yaw_fit_models[algo] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "940ed506",
   "metadata": {
    "id": "940ed506"
   },
   "outputs": [],
   "source": [
    "#use model on our train Dataset\n",
    "Train_pred_yaw = yaw_fit_models['rf_pca'].predict(X_train_y)\n",
    "\n",
    "#use model on our Validation Dataset\n",
    "Validation_pred_yaw = yaw_fit_models['rf_pca'].predict(X_val_y)\n",
    "\n",
    "#use model on our test Dataset\n",
    "yaw_hat=yaw_fit_models['rf_pca'].predict(X_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d334bab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1d334bab",
    "outputId": "3d28cc80-ed32-4850-9274-4774078eec27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE  0.010177408538945259\n",
      "Validation MSE  0.01817336333745248\n",
      "\n",
      "###########################\n",
      "\n",
      "Train r2_score  0.9695246337389682\n",
      "Validation r2_score  0.947810332177787\n",
      "Test r2_score  0.9459211910094788\n",
      "\n",
      "###########################\n",
      "\n",
      "Train score  0.9695246337389682\n",
      "Validation Score  0.947810332177787\n",
      "test score:  0.9459211910094788\n",
      "\n",
      "###########################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train MSE \"       , mean_squared_error( y_train_y,Train_pred_yaw ))\n",
    "print(\"Validation MSE \"  , mean_squared_error( y_val_y,Validation_pred_yaw ))\n",
    "\n",
    "print(\"\\n###########################\\n\")\n",
    "\n",
    "print(\"Train r2_score \"            , r2_score(y_train_y,Train_pred_yaw))\n",
    "print(\"Validation r2_score \"       , r2_score( y_val_y, Validation_pred_yaw))\n",
    "print(\"Test r2_score \"             , r2_score(y_test_y , yaw_hat))\n",
    "print(\"\\n###########################\\n\")\n",
    "\n",
    "print(\"Train score \"                   , yaw_fit_models['rf_pca'].score(X_train_y , y_train_y))\n",
    "print(\"Validation Score \"              , yaw_fit_models['rf_pca'].score(X_val_y, y_val_y))\n",
    "print(\"test score: \"                   ,yaw_fit_models ['rf_pca'].score(X_test_y, y_test_y))\n",
    " \n",
    "print(\"\\n###########################\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c3d69426",
   "metadata": {
    "id": "c3d69426"
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "#Saving model in pickle file, so we can use it just read it and use it\n",
    "with open('yaw_model.pkl', 'wb') as f:\n",
    "    pickle.dump(yaw_fit_models ['rf_pca'], f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2191f68e",
   "metadata": {
    "id": "2191f68e"
   },
   "source": [
    "# Roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8cd78015",
   "metadata": {
    "id": "8cd78015"
   },
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "\n",
    "    # 'rfpcap' :make_pipeline(PCA(n_components=0.99), RandomForestRegressor(n_estimators=200)),\n",
    "    'rfpcap':make_pipeline(MinMaxScaler(),PCA(n_components=0.98), \n",
    "    VotingRegressor(estimators=[('RF',rf),('Bagging',bagging),('Boosting',boosting),('SVM',svm)]))\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2a95b8d7",
   "metadata": {
    "id": "2a95b8d7"
   },
   "outputs": [],
   "source": [
    "roll_fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train_r, y_train_r)\n",
    "    roll_fit_models[algo] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "12554e09",
   "metadata": {
    "id": "12554e09"
   },
   "outputs": [],
   "source": [
    "Train_pred_roll     = roll_fit_models  ['rfpcap'].predict(X_train_r)\n",
    "Validation_pred_roll = roll_fit_models ['rfpcap'].predict(X_val_r)\n",
    "roll_hat             =roll_fit_models  ['rfpcap'].predict(X_test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5c884d9f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5c884d9f",
    "outputId": "aa101de8-6ed4-4fba-acc1-29d66ce825fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE  0.09518376248786642\n",
      "Validation MSE  0.013720471616231173\n",
      "\n",
      "###########################\n",
      "\n",
      "Train r2_score  0.8112878506244512\n",
      "Validation r2_score  0.8185937091383267\n",
      "Test r2_score  0.7323251235314374\n",
      "\n",
      "###########################\n",
      "\n",
      "Train score  0.8112878506244512\n",
      "Validation Score  0.8185937091383267\n",
      "test score:  0.7323251235314374\n",
      "\n",
      "###########################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train MSE \"       , mean_squared_error( y_train_r,Train_pred_roll ))\n",
    "print(\"Validation MSE \"  , mean_squared_error( y_val_r,Validation_pred_roll ))\n",
    "\n",
    "print(\"\\n###########################\\n\")\n",
    "\n",
    "print(\"Train r2_score \"            , r2_score(y_train_r,Train_pred_roll))\n",
    "print(\"Validation r2_score \"       , r2_score( y_val_r, Validation_pred_roll))\n",
    "print(\"Test r2_score \"             , r2_score(y_test_r , roll_hat))\n",
    "print(\"\\n###########################\\n\")\n",
    "\n",
    "print(\"Train score \"                   , roll_fit_models['rfpcap'].score(X_train_r , y_train_r))\n",
    "print(\"Validation Score \"              , roll_fit_models['rfpcap'].score(X_val_r, y_val_r))\n",
    "print(\"test score: \"                   , roll_fit_models ['rfpcap'].score(X_test_r, y_test_r))\n",
    " \n",
    "print(\"\\n###########################\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31c67035",
   "metadata": {
    "id": "31c67035"
   },
   "outputs": [],
   "source": [
    "with open('roll_model.pkl', 'wb') as f:\n",
    "    pickle.dump(roll_fit_models ['rfpcap'], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee3359d",
   "metadata": {
    "id": "9ee3359d"
   },
   "source": [
    "# PITCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f3af1014",
   "metadata": {
    "id": "f3af1014"
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "# ,('Boosting',boosting)\n",
    "# ,('Trees',trees)\n",
    "pipelines = {\n",
    "    'rf_pca':make_pipeline(MinMaxScaler(),PCA(n_components=0.99), RandomForestRegressor()),\n",
    "    # 'rf_pca':make_pipeline(MinMaxScaler(),PCA(n_components=0.99), VotingRegressor(estimators=[('Bagging',bagging),('SVM',svm),('Boosting',boosting),('Trees',trees)]))\n",
    "\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f0f464f3",
   "metadata": {
    "id": "f0f464f3"
   },
   "outputs": [],
   "source": [
    "pitch_fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train_p, y_train_p)\n",
    "    pitch_fit_models[algo] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "_ncJWuCJfwmf",
   "metadata": {
    "id": "_ncJWuCJfwmf"
   },
   "outputs": [],
   "source": [
    "Train_pred_pitch = pitch_fit_models['rf_pca'].predict(X_train_p)\n",
    "Validation_pred_pitch = pitch_fit_models['rf_pca'].predict(X_val_p)\n",
    "pitch_hat=pitch_fit_models['rf_pca'].predict(X_test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a6bb646",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4a6bb646",
    "outputId": "90d614d9-31f5-43c8-9138-58474a5356cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE  0.051302664824360036\n",
      "Validation MSE  0.02055480386181735\n",
      "\n",
      "###########################\n",
      "\n",
      "Train r2_score  0.857991010129622\n",
      "Validation r2_score  0.6792719275738812\n",
      "Test r2_score  0.6299871503728327\n",
      "\n",
      "###########################\n",
      "\n",
      "Train score  0.857991010129622\n",
      "Validation Score  0.6792719275738812\n",
      "test score:  0.6299871503728327\n",
      "\n",
      "###########################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Train MSE \"       , mean_squared_error( y_train_p, Train_pred_pitch))\n",
    "print(\"Validation MSE \"  , mean_squared_error( y_val_p,Validation_pred_pitch ))\n",
    "\n",
    "print(\"\\n###########################\\n\")\n",
    "\n",
    "print(\"Train r2_score \"            , r2_score(y_train_p,Train_pred_pitch))\n",
    "print(\"Validation r2_score \"       , r2_score( y_val_p, Validation_pred_pitch))\n",
    "print(\"Test r2_score \"             , r2_score(y_test_p , pitch_hat))\n",
    "print(\"\\n###########################\\n\")\n",
    "\n",
    "print(\"Train score \"                   , pitch_fit_models['rf_pca'].score(X_train_p , y_train_p))\n",
    "print(\"Validation Score \"              , pitch_fit_models['rf_pca'].score(X_val_p, y_val_p))\n",
    "print(\"test score: \"                   , pitch_fit_models ['rf_pca'].score(X_test_p, y_test_p))\n",
    " \n",
    "print(\"\\n###########################\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e29392ed",
   "metadata": {
    "id": "e29392ed"
   },
   "outputs": [],
   "source": [
    "with open('pitch_model.pkl', 'wb') as f:\n",
    "    pickle.dump(pitch_fit_models ['rf_pca'], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "43b326fe",
   "metadata": {
    "id": "43b326fe"
   },
   "outputs": [],
   "source": [
    "from math import cos ,sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053c7254",
   "metadata": {
    "id": "053c7254"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4da80b7",
   "metadata": {
    "id": "e4da80b7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa59fdce",
   "metadata": {
    "id": "aa59fdce"
   },
   "source": [
    "# Read Trained  MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "87ab6c21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "id": "87ab6c21",
    "outputId": "2c028b72-c7f6-480b-e8fd-0a29be31e0a3"
   },
   "outputs": [],
   "source": [
    "with open('yaw_model.pkl', 'rb') as f:\n",
    "    yaw_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c0bee972",
   "metadata": {
    "id": "c0bee972"
   },
   "outputs": [],
   "source": [
    "with open('pitch_model.pkl', 'rb') as f:\n",
    "    pitch_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1d66d9b2",
   "metadata": {
    "id": "1d66d9b2"
   },
   "outputs": [],
   "source": [
    "with open('roll_model.pkl', 'rb') as f:\n",
    "    roll_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c82b84b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfae7593",
   "metadata": {
    "id": "ccedb3e8"
   },
   "source": [
    "# Live Cam and Draw axis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a9a26370",
   "metadata": {
    "id": "a9a26370"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        image_height, image_width, _ = image.shape\n",
    "\n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        try:\n",
    "           \n",
    "            face = results.face_landmarks.landmark\n",
    "            NoseX = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].x * image_width\n",
    "            NoseY=results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].y   *image_height\n",
    "            LfeoX = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EYE_OUTER].x *image_width\n",
    "            LfeoY = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EYE_OUTER].y* image_height\n",
    "            \n",
    "            dist = math.dist([NoseX, NoseY], [LfeoX, LfeoY])\n",
    "            face_row = list(np.array([[   ((landmark.x *image_width)-NoseX)/dist, \n",
    "                                            ((landmark.y*image_height)-NoseY)/dist] for landmark in face]).reshape(1, -1))\n",
    "            \n",
    "#             print(face_row)\n",
    "            pitch = pitch_model.predict(face_row)\n",
    "            yaw = yaw_model.predict(face_row)\n",
    "            roll = roll_model.predict(face_row)\n",
    "            \n",
    "\n",
    "#             cv2_imshow(draw_axis(image,pitch,yaw,roll))\n",
    "            yaw = -yaw\n",
    "            tdx = NoseX\n",
    "            tdy = NoseY\n",
    "            size=100\n",
    "    # X-Axis pointing to right. drawn in red\n",
    "            x1 = size * (cos(yaw) * cos(roll)) + tdx\n",
    "            y1 = size * (cos(pitch) * sin(roll) + cos(roll) * sin(pitch) * sin(yaw)) + tdy\n",
    "\n",
    "    # Y-Axis | drawn in green\n",
    "    #        v\n",
    "            x2 = size * (-cos(yaw) * sin(roll)) + tdx\n",
    "            y2 = size * (cos(pitch) * cos(roll) - sin(pitch) * sin(yaw) * sin(roll)) + tdy\n",
    "\n",
    "    # Z-Axis (out of the screen) drawn in blue\n",
    "            x3 = size * (sin(yaw)) + tdx\n",
    "            y3 = size * (-cos(yaw) * sin(pitch)) + tdy\n",
    "            cv2.line(image, (int(tdx), int(tdy)), (int(x1),int(y1)),(0,0,255),3)\n",
    "            cv2.line(image, (int(tdx), int(tdy)), (int(x2),int(y2)),(0,255,0),3)\n",
    "            cv2.line(image, (int(tdx), int(tdy)), (int(x3),int(y3)),(255,0,0),2)\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "                \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        \n",
    "                        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "semi-Final Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
